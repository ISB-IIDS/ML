layer_dense(units = 10) %>%
layer_activation(activation = 'softmax')
#compiling the defined model with metric = accuracy and optimiser as adam.
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = c('accuracy')
)
#fitting the model on the training dataset
model %>% fit(train_x, train_y, epochs = 50, batch_size = 128)
#Evaluating model on the cross validation dataset
loss_and_metrics <- model %>% evaluate(test_x, test_y, batch_size = 128)
#fitting the model on the training dataset
model %>% fit(train_x, train_y, epochs = 20, batch_size = 128)
#Evaluating model on the cross validation dataset
loss_and_metrics <- model %>% evaluate(test_x, test_y, batch_size = 128)
#############################################################
?dataset_cifar10
cifar<-dataset_cifar10()
cifar<-dataset_cifar10()
# Save an object to a file
saveRDS(cifar, file = "dataset_cifar10.rds")
# Restore the object
cifar<-readRDS(file = "dataset_cifar10.rds")
#TRAINING DATA
train_x<-cifar$train$x/255
# visualize images
par(mfcol=c(4,4))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,1]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n')
}
#convert a vector class to binary class matrix
#converting the target variable to once hot encoded vectors using #keras inbuilt function 'to_categorical()train_y<-to_categorical(cifar$train$y,num_classes = 10)
#TEST DATA
test_x<-cifar$test$x/255
test_y<-to_categorical(cifar$test$y,num_classes=10)
#checking the dimentions
dim(train_x)
cat("No of training samples\t",dim(train_x)[[1]],"\tNo of test samples\t",dim(test_x)[[1]])
#a linear stack of layers
model<-keras_model_sequential()
#configuring the Model
model %>%
#defining a 2-D convolution layer
layer_conv_2d(filter=32,kernel_size=c(3,3),padding="same",                input_shape=c(32,32,3) ) %>%
layer_activation("relu") %>%
#another 2-D convolution layer
layer_conv_2d(filter=32 ,kernel_size=c(3,3))  %>%
layer_activation("relu") %>%
#Defining a Pooling layer which reduces the dimentions of the
#features map and reduces the computational complexity of the model
layer_max_pooling_2d(pool_size=c(2,2)) %>%
#dropout layer to avoid overfitting
layer_dropout(0.25) %>%
layer_conv_2d(filter=32 , kernel_size=c(3,3),padding="same") %>%
layer_activation("relu") %>%
layer_conv_2d(filter=32,kernel_size=c(3,3) ) %>%
layer_activation("relu") %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_dropout(0.25) %>%
#flatten the input
layer_flatten() %>%
layer_dense(512) %>%
layer_activation("relu") %>%
layer_dropout(0.5) %>%
#output layer-10 classes-10 units
layer_dense(10) %>%
#applying softmax nonlinear activation function to the output layer #to calculate cross-entropy
layer_activation("softmax")
#Model's Optimizer#defining the type of optimizer-ADAM-Adaptive Momentum Estimationopt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )#lr-learning rate , decay - learning rate decay over each update
model %>%
compile(loss="categorical_crossentropy",optimizer=opt,metrics = "accuracy")
#Summary of the Model and its Architecture
summary(model)
remove.packages("tensorflow")
library(R6)
# clear all variables
sessionInfo()
rm(list=ls())
sessionInfo()
# clear all variables
rm(list=ls())
# check folder
getwd()
try(require(keras))||install.packages("keras")
library(keras)
#############################################################
?dataset_cifar10
cifar<-dataset_cifar10()
# Save an object to a file
saveRDS(cifar, file = "dataset_cifar10.rds")
# Restore the object
cifar<-readRDS(file = "dataset_cifar10.rds")
#TRAINING DATA
train_x<-cifar$train$x/255
# visualize images
par(mfcol=c(4,4))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,1]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,1]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,2]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,3]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,3]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,2]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,2]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,1]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,3]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, xaxt='n')
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,3]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n')
}
#############################################################
?dataset_cifar10
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:16) {
im <- train_x[idx,,,3]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n', main=paste(train_y[idx]))
}
#TRAINING DATA
train_x<-cifar$train$x/255
train_x<-cifar$train$y/255
#TRAINING DATA
train_x<-cifar$train$x/255
train_y<-cifar$train$y/255
View(train_y)
#TRAINING DATA
train_x<-cifar$train$x/255
train_y<-cifar$train$y
View(train_y)
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:36) {
im <- train_x[idx,,,3]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n', main=paste(train_y[idx]))
}
# visualize images
par(mfcol=c(6,6))
par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')
for (idx in 1:36) {
im <- train_x[idx,,,1]
im <- t(apply(im, 2, rev))
image(1:32, 1:32, im, col=gray((0:255)/255),xaxt='n', main=paste(train_y[idx]))
}
#convert a vector class to binary class matrix
#converting the target variable to once hot encoded vectors using #keras inbuilt function 'to_categorical()train_y<-to_categorical(cifar$train$y,num_classes = 10)
#TEST DATA
test_x<-cifar$test$x/255
test_y<-to_categorical(cifar$test$y,num_classes=10)
#checking the dimentions
dim(train_x)
cat("No of training samples\t",dim(train_x)[[1]],"\tNo of test samples\t",dim(test_x)[[1]])
#a linear stack of layers
model<-keras_model_sequential()
#configuring the Model
model %>%
#defining a 2-D convolution layer
layer_conv_2d(filter=32,kernel_size=c(3,3),padding="same",                input_shape=c(32,32,3) ) %>%
layer_activation("relu") %>%
#another 2-D convolution layer
layer_conv_2d(filter=32 ,kernel_size=c(3,3))  %>%
layer_activation("relu") %>%
#Defining a Pooling layer which reduces the dimentions of the
#features map and reduces the computational complexity of the model
layer_max_pooling_2d(pool_size=c(2,2)) %>%
#dropout layer to avoid overfitting
layer_dropout(0.25) %>%
layer_conv_2d(filter=32 , kernel_size=c(3,3),padding="same") %>%
layer_activation("relu") %>%
layer_conv_2d(filter=32,kernel_size=c(3,3) ) %>%
layer_activation("relu") %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_dropout(0.25) %>%
#flatten the input
layer_flatten() %>%
layer_dense(512) %>%
layer_activation("relu") %>%
layer_dropout(0.5) %>%
#output layer-10 classes-10 units
layer_dense(10) %>%
#applying softmax nonlinear activation function to the output layer #to calculate cross-entropy
layer_activation("softmax")
#Model's Optimizer#defining the type of optimizer-ADAM-Adaptive Momentum Estimationopt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )#lr-learning rate , decay - learning rate decay over each update
model %>%
compile(loss="categorical_crossentropy",optimizer=opt,metrics = "accuracy")
#for computing Probabilities of classes-"logit(log probabilities)
?complie
#for computing Probabilities of classes-"logit(log probabilities)
?compile.keras.engine.training.Model
#Model's Optimizer#defining the type of optimizer-ADAM-Adaptive Momentum Estimationopt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )#lr-learning rate , decay - learning rate decay over each update
model %>%
compile(loss="categorical_crossentropy",optimizer=adam,metrics = "accuracy")
#Model's Optimizer#defining the type of optimizer-ADAM-Adaptive Momentum Estimationopt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )#lr-learning rate , decay - learning rate decay over each update
model %>%
compile(loss="categorical_crossentropy",optimizer="opt",metrics = "accuracy")
#Model's Optimizer#defining the type of optimizer-ADAM-Adaptive Momentum Estimationopt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )#lr-learning rate , decay - learning rate decay over each update
model %>%
compile(loss="categorical_crossentropy",optimizer="adam",metrics = "accuracy")
#Model's Optimizer#defining the type of optimizer-ADAM-Adaptive Momentum Estimationopt<-optimizer_adam( lr= 0.0001 , decay = 1e-6 )#lr-learning rate , decay - learning rate decay over each update
model %>%
compile(loss="categorical_crossentropy",optimizer="adam",metrics = "accuracy")
#Summary of the Model and its Architecture
summary(model)
install.packages(c("mlogit", "readxl", "tidyr"))
try(require(mlogit) || install.packages("mlogit",dependencies = TRUE))
try(require(mlogit) || install.packages("mlogit",dependencies = TRUE))
try(require(readxl) || install.packages("readxl",dependencies = TRUE))
try(require(tidyr) || install.packages("tidyr",dependencies = TRUE))
try(require(mlogit) || install.packages("mlogit",dependencies = TRUE))
try(require(readxl) || install.packages("readxl",dependencies = TRUE))
try(require(tidyr) || install.packages("tidyr",dependencies = TRUE))
ChoiceData <- data.frame()
ChoiceData <- read_excel("ABB Logit Exercise.xlsx", sheet = "ABB", skip = 3, col_names = TRUE)
ChoiceData$Customer <- gsub("^\\s+|\\s+$", "", ChoiceData$Customer)
getwd()
# Bi Plot App
source("https://raw.githubusercontent.com/sudhir-voleti/biplot-shinyapp/master/dependency-biplot-shinyapp.R")
runGitHub("biplot-shinyapp","sudhir-voleti")
# Segmentation-discriminant-targeting App
source("https://raw.githubusercontent.com/sudhir-voleti/segmentation-discriminant-and-targeting-shinyapp/master/dependency-segmentation-discriminant-and-targeting-shinyapp.R")
runGitHub("segmentation-discriminant-and-targeting-shinyapp","sudhir-voleti")
# Likart Visualization App
source("https://raw.githubusercontent.com/sudhir-voleti/likert-visualization-shinyapp/master/dependency-likert-visualization-shinyapp.R")
runGitHub("likert-visualization-shinyapp","sudhir-voleti")
# Install packages
install.packages("readr")
install.packages("dplyr")
install.packages("DataExplorer")
# Load packages
library(dplyr)
library(ggplot2)
library(readr)
library(DataExplorer)
# Load data
sales_data <- read.csv("data/s4.csv",stringsAsFactors=FALSE)
# Review data
str(sales_data)
View(sales_data)
summary(sales_data)
# Create recency
sales_data$Recency <- round(as.numeric(difftime(Sys.Date(),
sales_data[,3],units="days")) )
# Creation of Recency, Frequency y Monetary
salesM <- aggregate(sales_data[,2],list(sales_data$idCustomer),sum)
names(salesM) <- c("idCustomer","Monetary")
salesF <- aggregate(sales_data[,2],list(sales_data$idCustomer),length)
names(salesF) <- c("idCustomer","Frequency")
salesR <- aggregate(sales_data[,4],list(sales_data$idCustomer),min)
names(salesR) <- c("idCustomer","Recency")
# Combination R,F,M
temp <- merge(salesF,salesR,"idCustomer")
salesRFM <- merge(temp,salesM,"idCustomer")
#  Creation of R,F,M rank
salesRFM$rankR <- cut(salesRFM$Recency,5,labels=F)
salesRFM$rankF <- cut(salesRFM$Frequency,5,labels=F)
salesRFM$rankM <- cut(salesRFM$Monetary,5,labels=F)
# Review top 10
salesRFM <- salesRFM[with(salesRFM, order(-rankR, -rankF, -rankM)), ]
head(salesRFM, n=10)
# Analysis
groupRFM <- count(salesRFM, rankR, rankF,rankM)
groupRFM <- salesRFM$rankR*100 + salesRFM$rankF*10 +
salesRFM$rankM
salesRFM <- cbind(salesRFM,groupRFM)
# Plot
ggplot(salesRFM, aes(factor(groupRFM))) +
geom_bar() +
ggtitle('Customer Distribution by RFM') +
labs(x="RFM",y="# Customers") +
theme(plot.title = element_text(color="#666666", face="bold", size=16, hjust=0)) +
theme(axis.title = element_text(color="#666666", face="bold"))
shiny::runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/segmentation-shinyapp')
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
https://raw.githubusercontent.com/ISB-IIDS/ML/main/basic-text-analysis-shinyapp/dependency-basic-text-analysis-shinyapp.R
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/basic-text-analysis-shinyapp/dependency-basic-text-analysis-shinyapp.R")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/dependency-factor-analysis-shinyapp.R")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
runGitHub("factor-analysis-shinyapp","sudhir-voleti")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS", subdir="/factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp/")
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis-shinyapp/")
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis/")
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis/")
library(shiny)
runGitHub("ML","Manish-Gangwar", subdir="ols-regression")
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/factor-analysis')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis/")
library(shiny)
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis/")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp/")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp/")
shiny::runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/Mlogit')
try(require(mlogit) || install.packages("mlogit",dependencies = TRUE))
try(require(readxl) || install.packages("readxl",dependencies = TRUE))
try(require(tidyr) || install.packages("tidyr",dependencies = TRUE))
getwd()
ChoiceData <- data.frame()
ChoiceData <- read_excel("ABB Logit Exercise.xlsx", sheet = "ABB", skip = 3, col_names = TRUE)
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp/")
library(shiny)
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp/")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp/")
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis-shinyapp/")
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis")
source(https://raw.githubusercontent.com/Manish-Gangwar/ML/master/factor-analysis/server.R)
source(https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/dependency-factor-analysis-shinyapp.R)
source("https://raw.githubusercontent.com/sudhir-voleti/factor-analysis-shinyapp/master/dependency-factor-analysis-shinyapp.R")
source(https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/server.R)
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/server.R")
runGitHub("ML","Manish-Gangwar", subdir="factor-analysis")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS", subdir="factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS",ref="main"", subdir="factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS",ref="main"", subdir="factor-analysis-shinyapp/")
runGitHub("ML","ISB-IIDS", ref="main"", subdir="factor-analysis-shinyapp/")
runGitHub("ML","ISB-IIDS", ref="main", subdir="factor-analysis-shinyapp/")
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/dependency-factor-analysis-shinyapp.R")
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/dependency-factor-analysis-shinyapp.R")
runGitHub("ML","ISB-IIDS", ref="main", subdir="factor-analysis-shinyapp/")
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/factor-analysis-shinyapp/dependency-factor-analysis-shinyapp.R")
runGitHub("ML","ISB-IIDS", ref="main", subdir="factor-analysis-shinyapp/")
runGitHub("ML","ISB-IIDS", ref="main", subdir="dependency-ML")
library(shiny)
runGitHub("ML","ISB-IIDS", ref="main", subdir="dependency-ML")
runGitHub("ML","ISB-IIDS", ref="main", subdir="dependency-ML/")
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/dependency-ML.R")
source("https://raw.githubusercontent.com/ISB-IIDS/ML/main/dependency-ML.R")
runGitHub("ML","ISB-IIDS", ref="main", subdir="factor-analysis-shinyapp")
runGitHub("ML","ISB-IIDS", ref="main", subdir="pls-regression")
library(shiny)
runGitHub("ML","ISB-IIDS", ref="main", subdir="ols-regression")
runGitHub("ML","ISB-IIDS", ref="main", subdir="ols-regression")
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
runGitHub("ML","ISB-IIDS", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="ols-regression")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="factor-analysis")
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
install.packages("PerformanceAnalytics")
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="ols-regression")
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="ols-regression")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="ols-regression")
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/ols-regression')
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="ols-regression")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="factor-analysis")
mtcars{datasets}
?mtcars
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="factor-analysis")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="main", subdir="decision-tree-CART")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="main", subdir="factor-analysis")
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="decision-tree-CART")
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="decision-tree-CART")
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ELP2020/decision-tree-CART')
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="decision-tree-CART")
shiny::runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ELP2020/decision-tree-CART')
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="decision-tree")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="decision-tree")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="decision-tree")
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="factor-analysis")
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="decision-tree-CART")
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ELP2020", "Manish-Gangwar", ref="main", subdir="ols-regression")
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ML", "Manish-Gangwar", ref="master", subdir="ols-regression")
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ML/ols-regression')
library(shiny); runGitHub("ML", "ISB-IIDS", ref="master", subdir="ols-regression")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="ols-regression")
library(shiny); runGitHub("ML", "ISB-IIDS", ref="main", subdir="ols-regression")
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ISB-IIDS/ML/ols-regression')
shiny::runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/Mlogit Wide')
pricing_final_new <- read.csv("D:/OneDrive - Indian School of Business/Desktop2019/Data Driven Decison Making/pricing_final_new.csv")
View(pricing_final_new)
data<-read.csv("pricing_final_new.csv")
mldata = dfidx(data,choice = "exam_category",varying = 10:12,sep=".",shape = "wide",idx = "id")
View(pricing_final_new)
#data<-read.csv("pricing_final_new.csv")
mldata = dfidx(data,choice = "exam_category",varying = 10:12,sep=".",shape = "wide",idx = "id")
summary(pricing_final_new)
mldata = dfidx(pricing_final_new,choice = "exam_category",varying = 10:12,sep=".",shape = "wide",idx = "id")
summary(mldata)
desc(mldata)
mlogit.model1 <- mlogit(exam_category ~ price| surg_age  + surg_eye + gender, data = mldata)
mlogit.model1 <- mlogit(exam_category ~ price|0+ surg_age  + surg_eye + gender, data = mldata)
summary(mlogit.model1)
mlogit.model1 <- mlogit(exam_category ~ price|1+ surg_age  + surg_eye + gender, data = mldata)
mlogit.model1 <- mlogit(exam_category ~ price| surg_age  + surg_eye + gender, data = mldata)
mlogit.model1 <- mlogit(exam_category ~ 0+price|0+ surg_age  + surg_eye + gender, data = mldata)
mlogit.model1 <- mlogit(exam_category ~ 0+price|1+ surg_age  + surg_eye + gender, data = mldata)
mlogit.model1 <- mlogit(exam_category ~ 0|surg_age  + surg_eye + gender, data = mldata)
(mldata)[1]
(mldata)[[1]]
(mldata)[[1]]
(mldata)[[2]]
(mldata)[[3]]
colnames(mldata)
runApp('D:/Indian School of Business/VishalSiram Anil - R shiny App/Mlogit Wide')
setdiff(colnames(mldata),
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ISB-IIDS/ML/m-logit')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ISB-IIDS/ML/m-logit')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ISB-IIDS/ML/m-logit')
runApp('D:/OneDrive - Indian School of Business/Laptop sync/Desktop/GitHub/Manish-Gangwar/ISB-IIDS/ML/binary-logit')
